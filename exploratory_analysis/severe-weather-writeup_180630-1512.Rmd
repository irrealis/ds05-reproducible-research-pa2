---
title: "Health and Financial Impact of Severe-Weather Events Between 2005 and 2011"
---

```{r , eval=F, include=F, results="hide"}
setwd("/media/kaben/Work/Repos/irrealis/ds05-reproducible-research-pa2/exploratory_analysis/")
```

# Synopsis

# Data Processing

We begin by loading required libraries _data.table_ and _dplyr_ for data manipulation, _lubridate_ for handling dates, and _ggplot2_ for plotting.

```{r }
library(data.table)
library(ggplot2)
library(dplyr)
library(lubridate)
```

We set hard-coded analysis parameters, most importantly the raw data URL. The remaining convenience parameters organize analysis files.

```{r }
# Data subdirectory.
dat_dir <- "data"
# Raw data subdirectory.
raw_dir <- file.path(dat_dir, "raw")
# Intermediate data subdirectory.
int_dir <- file.path(dat_dir, "intermediate")
# Clean data subdirectory.
cln_dir <- file.path(dat_dir, "processed")

# Raw-data URL.
raw_url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
# Raw-data filename.
raw_fnm <- "StormData.csv.bz2"
# Raw-data path.
raw_pth <- file.path(raw_dir, raw_fnm)
```

We create any missing analysis subdirectories.

```{r }
if(!dir.exists(dat_dir)){ dir.create(dat_dir) }
if(!dir.exists(raw_dir)){ dir.create(raw_dir) }
if(!dir.exists(int_dir)){ dir.create(int_dir) }
if(!dir.exists(cln_dir)){ dir.create(cln_dir) }
```

We define a convenience function to load raw data, downloading and caching if missing.

```{r }
fetch_if_missing_then_load <- function(url_, raw_pth_, dat_pth_){
    if(!file.exists(dat_pth_)){
        if(!file.exists(raw_pth_)){ download.file(url_, raw_pth_) }
        fwrite(read.csv(raw_pth_), dat_pth_)
    }
    fread(dat_pth_)
}
```

We then load raw data.

```{r }
dat <- fetch_if_missing_then_load(raw_url, raw_pth, cch_pth)
```

This analysis uses the following columns:

- `EVTYPE` (weather-event types)
- `FATALITIES` and `INJURIES`
- `PROPDMG` and `PROPDMGEXP` (property-damage values)
- `CROPDMG` and `CROPDMGEXP` (crop-damage values)
- `BGN_DATE`, `BGN_TIME`, and `TIME_ZONE` (weather-event starting dates and times)

We discard all others.

```{r }
dat <- dat %>%
    select(
        EVTYPE, BGN_DATE, BGN_TIME, TIME_ZONE,
        PROPDMG, PROPDMGEXP, CROPDMG, CROPDMGEXP, FATALITIES, INJURIES
    ) %>%
    data.table()
```


### Initial assessment of dataset quality: event types

From section 2.1 of the [National Weather Service (NWS) storm data documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) we expect 48 permitted storm data event types, but find `r length(unique(dat$EVTYPE))` distinct types in our data.

```{r }
length(unique(dat$EVTYPE))
```

The first few events suggest that spelling variants and event conflations are causes. For example, `TSTM WIND`, `THUNDERSTORM WINDS`, `THUNDERSTORM WIND`, `THUNDERSTORM WINS` all appear to represent "Thunderstorm Wind", and `HURRICANE OPAL/HIGH WINDS` represents two separate (if related) event types.

```{r }
unique(dat$EVTYPE)[1:20]
```

Some `r length(dat[grepl("Summary", EVTYPE, ignore.case = F), EVTYPE])` rows appear to summarize other events, but record no injuries, fatalities, or property/crop damage, so should be excluded from analysis.

```{r }
dat[grepl("Summary", EVTYPE, ignore.case = F), EVTYPE][1:5]
sum(dat[grepl("Summary", EVTYPE, ignore.case = F), c(INJURIES, FATALITIES, PROPDMG, CROPDMG)])
```

Only three event types are recorded for the 1950s (and only `r unique(dat[grepl("1951", BGN_DATE, ignore.case = F), EVTYPE])` events for the early '50s).

```{r }
unique(dat[grepl("195[[:digit:]]", BGN_DATE, ignore.case = F), EVTYPE])
```

The [National Oceanic and Atmospheric Administration (NOAA) Storm Events Database page](https://www.ncdc.noaa.gov/stormevents/details.jsp) states that only tornado events are represented for 1950 through 1954, and tornado, thunderstorm wind, and hail for 1955 through 1995, which seems to agree with our findings. But it also states that 48 event types are used for 1996 to present, which disagrees with our `r length(unique(dat$EVTYPE))` distinct types. On the other hand, this suggests that constructing a time series may help to identify and extract a dataset suitable for analysis.


### Time series construction

Accordingly we synthesize a `begin_datetime` field for each row using `BGN_DATE`, `BGN_TIME`, and `TIME_ZONE`. We first transform `TIME_ZONE` for compatibility with _R_ and _lubridate_. Of the distinct values of `TIME_ZONE`, two appear to be capitalization variants of "EST" and "CST" (`ESt` and `CSt`, respectively), one appears to represent "Unknown" (`UNK`), and three appear to be misspellings (`ESY`, `CSC`, and `SCT`).

```{r }
unique(dat$TIME_ZONE)
```

We construct and apply the transformation, then remove rows with unknown or misspelled values for `TIME_ZONE`.

```{r }
timezone_transform <- data.frame(rbind(
    c("SST", "Etc/GMT-11"), # Samoa
    c("GST", "Etc/GMT-10"), # Guam
    c("UNK", "NA"), # Unknown
    c("UTC", "Etc/GMT+0"),
    c("GMT", "Etc/GMT+0"), # UTC
    c("ADT", "Etc/GMT+3"),
    c("AST", "Etc/GMT+4"),
    c("EDT", "Etc/GMT+4"),
    c("EST", "Etc/GMT+5"),
    c("ESt", "Etc/GMT+5"), # EST
    c("ESY", "NA"), # EST
    c("CDT", "Etc/GMT+5"),
    c("CST", "Etc/GMT+6"),
    c("CSt", "Etc/GMT+6"), # CST
    c("CSC", "NA"), # CST
    c("SCT", "NA"), # CST
    c("MDT", "Etc/GMT+6"),
    c("MST", "Etc/GMT+7"),
    c("PDT", "Etc/GMT+7"),
    c("PST", "Etc/GMT+8"),
    c("AKS", "Etc/GMT+9"),
    c("HST", "Etc/GMT+10")
))
names(timezone_transform) <- c("TIME_ZONE", 'timezone')
dat <- merge(dat, timezone_transform, sort=F)
rows_removed <- nrow(dat[timezone == "NA",])
dat <- dat[timezone != "NA",]
```

This has removed `r rows_removed` rows. We also remove rows with bad `BGN_TIME` values.


```{r }
begin_times <- parse_date_time(dat$BGN_TIM, c("HM", "HMS"))
bad_begin_times <- dat[is.na(begin_times), BGN_TIME]
dat <- dat[!is.na(begin_times)]
```

This has removed `r length(bad_begin_times)` rows with begin times `r bad_begin_times`. We now synthesize `begin_datetime` values.

```{r }
convert_to_datetime <- function(date_, time_, tz_){
    psx_date_ <- parse_date_time(date_, "mdY HMS")
    psx_time_ <- parse_date_time(time_, c("HM", "HMS"))
    make_datetime(
        year = year(psx_date_),
        month = month(psx_date_),
        day = day(psx_date_),
        hour = hour(psx_time_),
        min = minute(psx_time_),
        tz = as.character(tz_)
    )
}
dat[, begin_datetime := convert_to_datetime(BGN_DATE, BGN_TIME, timezone)]
```

This permits vizualizing the dataset's evolution, and that of `EVTYPE` values in particular.


### Visualization of `EVTYPE` evolution

We first extract the number of different event types used each year.

```{r }
counts_by_year <- dat %>%
    transmute(year = year(with_tz(begin_datetime, 'Etc/GMT+0')), EVTYPE) %>%
    unique() %>%
    count(year) %>%
    data.table()
```

We add to this the number of new event types added or removed each year.

```{r }
uses <- do.call(data.table, with(dat,
    aggregate(
        cbind(years = year(begin_datetime)),
        by = list(event_type = EVTYPE),
        function(yr) c(first = min(yr), last = max(yr))
    )
)) %>%
    mutate(years_used = years.last - years.first + 1)
additions <- uses %>%
    count(year = years.first) %>%
    select(year, added = n)
removals <- uses %>%
    count(year = years.last + 1) %>%
    select(year, removed = n)
updates <- counts_by_year %>%
    merge(additions, all=T ) %>%
    merge(removals, all=T) %>%
    {.[is.na(.)] <- 0; .} %>%
    mutate(active = cumsum(added) - cumsum(removed)) %>%
    select(-n) %>%
    filter(year < 2012)
```

We can now visualize the number of actively-used events each year, as well as additions of new types and retirements of old types.

```{r }
long_updates <- updates %>% melt(id.var = c('year'), value.name = 'count')
ggplot(long_updates, aes(x=year, y=count, color=variable)) + geom_line()
```

Over 400 new event are added between about 1993 and 1995, the majority of which are retired within a few years. The number of actively-used events continues to decline for a decade before stabilizing slightly below 50 around 2005. After 2006, exactly `r counts_by_year[2007 == year, n]` are used in each year.

```{r }
counts_by_year[2005 <= year,]
```

The number of distinct event types used between 2007 and 2011 is
`r length(unique(dat[(ymd("2007-1-1", tz='Etc/GMT+0') <= begin_datetime), EVTYPE]))`.

```{r }
event_types <- unique(dat[(ymd("2007-1-1", tz='Etc/GMT+0') <= begin_datetime), EVTYPE])
sort(event_types)
length(event_types)
```

These types are exactly the permitted storm data events listed in table 1, section 2.1.1 of the [National Weather Service Instruction (NWSI) 10-1605](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) dated August 17, 2007 (which, provided to us by our instructors, has in its publication date a hint).


### Extracting permitted events

Our usable data is thus limited to the period from 2007 through 2011. We extract this period for further processing.

```{r }
dat <- dat[(ymd("2007-1-1", tz='Etc/GMT+0') <= begin_datetime),]
```

To simplify troubleshooting, we map `EVTYPE` to names listed in table 1, section 2.1.1 of NWSI 10-1605. In particular, `LANDSLIDE` maps to "Debris Flow", `HURRICANE` to "Hurricane (Typhoon)", and `VOLCANIC ASHFALL` to "Volcanic Ash". All other mappings simply change capitalization.
```{r }
event_transform <- data.frame(rbind(
    c("ASTRONOMICAL LOW TIDE", "Astronomical Low Tide"),
    c("AVALANCHE", "Avalanche"),
    c("BLIZZARD", "Blizzard"),
    c("COASTAL FLOOD", "Coastal Flood"),
    c("COLD/WIND CHILL", "Cold/Wind Chill"),
    c("LANDSLIDE", "Debris Flow"),
    c("DENSE FOG", "Dense Fog"),
    c("DENSE SMOKE", "Dense Smoke"),
    c("DROUGHT", "Drought"),
    c("DUST DEVIL", "Dust Devil"),
    c("DUST STORM", "Dust Storm"),
    c("EXCESSIVE HEAT", "Excessive Heat"),
    c("EXTREME COLD/WIND CHILL", "Extreme Cold/Wind Chill"),
    c("FLASH FLOOD", "Flash Flood"),
    c("FLOOD", "Flood"),
    c("FREEZING FOG", "Freezing Fog"),
    c("FROST/FREEZE", "Frost/Freeze"),
    c("FUNNEL CLOUD", "Funnel Cloud"),
    c("HAIL", "Hail"),
    c("HEAT", "Heat"),
    c("HEAVY RAIN", "Heavy Rain"),
    c("HEAVY SNOW", "Heavy Snow"),
    c("HIGH SURF", "High Surf"),
    c("HIGH WIND", "High Wind"),
    c("HURRICANE", "Hurricane (Typhoon)"),
    c("ICE STORM", "Ice Storm"),
    c("LAKE-EFFECT SNOW", "Lake-Effect Snow"),
    c("LAKESHORE FLOOD", "Lakeshore Flood"),
    c("LIGHTNING", "Lightning"),
    c("MARINE HAIL", "Marine Hail"),
    c("MARINE HIGH WIND", "Marine High Wind"),
    c("MARINE STRONG WIND", "Marine Strong Wind"),
    c("MARINE THUNDERSTORM WIND", "Marine Thunderstorm Wind"),
    c("RIP CURRENT", "Rip Current"),
    c("SEICHE", "Seiche"),
    c("SLEET", "Sleet"),
    c("STORM SURGE/TIDE", "Storm Surge/Tide"),
    c("STRONG WIND", "Strong Wind"),
    c("THUNDERSTORM WIND", "Thunderstorm Wind"),
    c("TORNADO", "Tornado"),
    c("TROPICAL DEPRESSION", "Tropical Depression"),
    c("TROPICAL STORM", "Tropical Storm"),
    c("TSUNAMI", "Tsunami"),
    c("VOLCANIC ASHFALL", "Volcanic Ash"),
    c("WATERSPOUT", "Waterspout"),
    c("WILDFIRE", "Wildfire"),
    c("WINTER STORM", "Winter Storm"),
    c("WINTER WEATHER", "Winter Weather")
))
names(event_transform) <- c("EVTYPE", "event_type")
dat <- merge(dat, event_transform, sort=F)
```


### Transforming property- and crop-damage data

Our property- and crop-damage data appear as fields `PROPDMG/CROPDMG` (numeric) and `PROPDMGEXP/CROPDMGEXP` (character). The former appear to be significands, and the latter exponents that we now explore.

```{r }
unique(dat[, PROPDMGEXP])
unique(dat[, CROPDMGEXP])
```

The symbol '0' is used once with `PROPDMG` value also zero, so can be assumed to represent 1e0.

```{r }
dat[(PROPDMGEXP == '0') | (CROPDMGEXP == '0'),]
```

Use of symbols 'K' (thousands), 'M' (millions), and 'B' (billions) is consistent with NWSI 10-1605 documentation. Thus we apply the following transformation:

```{r }
damage_exponent_transform <- data.frame(rbind(
    c("B", 1e9), # Billion
    c("M", 1e6), # Million
    c("K", 1e3), # Thousand
    c("0", 1e0)  # One
))
names(damage_exponent_transform) <- c("PROPDMGEXP", 'property_damage_multiplier')
dat <- merge(dat, damage_exponent_transform, sort=F)
names(damage_exponent_transform) <- c("CROPDMGEXP", 'crop_damage_multiplier')
dat <- merge(dat, damage_exponent_transform, sort=F)
```

We can now synthesize property- and crop-damage values.

```{r }
dat[, property_damage := PROPDMG * as.numeric(property_damage_multiplier)]
dat[, crop_damage := CROPDMG * as.numeric(crop_damage_multiplier)]
```

### Tidying

Our final processing step removes unused fields.

```{r }
tidy <- dat %>%
    select(
        begin_datetime,
        event_type,
        injuries = INJURIES,
        fatalities = FATALITIES,
        property_damage,
        crop_damage,
    )
str(tidy)
```

These fields have the following meaning:

- `event_type`: One of 48 permitted storm-event types listed in NWSI 10-1605 as of August 17, 2007. Type: factor.
- `begin_datetime`: Date and time at start of event. Type: `POSIXct`.
- `injuries`: Number of direct injuries caused by event. Type: integer.
- `fatalities`: Number of direct fatalities caused by event. Type: integer.
- `property_damage`: Dollar amount of direct property damage caused by event. Type: numeric.
- `crop_damage`: Dollar amount of direct crop damage caused by event. Type: numeric.


# Results

```{r , eval=F, include=F, results="hide"}
library(rmarkdown)
rmarkdown::render(
    "severe-weather-writeup_180630-1512.Rmd",
    output_dir = "text",
    clean = T
)
```
