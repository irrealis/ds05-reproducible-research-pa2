---
title: "Health and Financial Impact of Severe-Weather Events Between 2005 and 2011"
---

```{r , eval=F, include=F, results="hide"}
setwd("/media/kaben/Work/Repos/irrealis/ds05-reproducible-research-pa2/exploratory_analysis/")
```

# Synopsis

# Data Processing

We begin by loading required libraries _data.table_ and _dplyr_ for data manipulation, _lubridate_ for handling dates, and _ggplot2_ for plotting.

```{r }
library(data.table)
library(ggplot2)
library(dplyr)
library(lubridate)
```

We set hard-coded analysis parameters, most importantly the raw data URL. The remaining convenience parameters organize analysis files.

```{r }
# Data subdirectory.
dat_dir <- "data"
# Raw data subdirectory.
raw_dir <- file.path(dat_dir, "raw")
# Intermediate data subdirectory.
int_dir <- file.path(dat_dir, "intermediate")
# Clean data subdirectory.
cln_dir <- file.path(dat_dir, "processed")

# Raw-data URL.
raw_url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
# Raw-data filename.
raw_fnm <- "StormData.csv.bz2"
# Raw-data path.
raw_pth <- file.path(raw_dir, raw_fnm)

# Cached data.
cch_fnm <- "StormData.csv"
cch_pth <- file.path(int_dir, cch_fnm)

# Tidy data.
tdy_fnm <- "StormData-Tidy.csv"
tdy_pth <- file.path(cln_dir, tdy_fnm)
```

We create missing analysis subdirectories.

```{r }
if(!dir.exists(dat_dir)){ dir.create(dat_dir) }
if(!dir.exists(raw_dir)){ dir.create(raw_dir) }
if(!dir.exists(int_dir)){ dir.create(int_dir) }
if(!dir.exists(cln_dir)){ dir.create(cln_dir) }
```

We define a convenience function to load raw data, downloading and caching if missing.

```{r }
fetch_if_missing_then_load <- function(url_, raw_pth_, dat_pth_){
    if(!file.exists(dat_pth_)){
        if(!file.exists(raw_pth_)){ download.file(url_, raw_pth_) }
        fwrite(read.csv(raw_pth_), dat_pth_)
    }
    fread(dat_pth_)
}
```

We load raw data.

```{r }
dat <- fetch_if_missing_then_load(raw_url, raw_pth, cch_pth)
```

We will process the following columns. We discard the rest.

- `EVTYPE` (weather-event types)
- `FATALITIES` and `INJURIES`
- `PROPDMG` and `PROPDMGEXP` (property-damage values)
- `CROPDMG` and `CROPDMGEXP` (crop-damage values)
- `BGN_DATE`, `BGN_TIME`, and `TIME_ZONE` (weather-event starting dates and times)

```{r }
dat <- dat %>%
    select(
        EVTYPE, BGN_DATE, BGN_TIME, TIME_ZONE,
        PROPDMG, PROPDMGEXP, CROPDMG, CROPDMGEXP, FATALITIES, INJURIES
    ) %>%
    data.table()
```


### Initial quality assessment: event types

From section 2.1 of the [National Weather Service (NWS) storm data documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) we expect 48 storm data event types, but find `r length(unique(dat$EVTYPE))`.

```{r }
length(unique(dat$EVTYPE))
```

Causes include spelling variants and event conflations. For example, `TSTM WIND`, `THUNDERSTORM WINDS`, `THUNDERSTORM WIND`, `THUNDERSTORM WINS` all appear to represent "Thunderstorm Wind", while `HURRICANE OPAL/HIGH WINDS` conflates two distinct event types. Use of spelling variants requires extensive curation during processing. Event conflation suggests different recording methods at different times, which may prevent comparative analysis.

```{r }
unique(dat$EVTYPE)[1:20]
```

Only three event types are recorded for the 1950s (and only `r unique(dat[grepl("1951", BGN_DATE, ignore.case = F), EVTYPE])` events for the early '50s). This indicates sampling of different populations at different times, which may prevent comparative analysis.

```{r }
unique(dat[grepl("195[[:digit:]]", BGN_DATE, ignore.case = F), EVTYPE])
```

The [National Oceanic and Atmospheric Administration (NOAA) Storm Events Database page](https://www.ncdc.noaa.gov/stormevents/details.jsp) states that only tornado events are represented for 1950 through 1954, and tornado, thunderstorm wind, and hail for 1955 through 1995, which seems to agree with our findings. But it also states that 48 event types are used for 1996 to present, which disagrees with our `r length(unique(dat$EVTYPE))` distinct types. On the other hand, this suggests that constructing a time series may help to identify and extract a dataset suitable for our analysis.


### Time series construction

Accordingly we synthesize a `begin_datetime` field for each row using `BGN_DATE`, `BGN_TIME`, and `TIME_ZONE`. We transform `TIME_ZONE` values for compatibility with _R_ and _lubridate_. Of the distinct values, two appear to be capitalization variants of "EST" and "CST" (`ESt` and `CSt`, respectively), one appears to represent "Unknown" (`UNK`), and three appear to be misspellings (`ESY`, `CSC`, and `SCT`).

```{r }
unique(dat$TIME_ZONE)
```

We construct and apply the transformation, then remove rows with unknown or misspelled `TIME_ZONE` values.

```{r }
timezone_transform <- data.frame(rbind(
    c("SST", "Etc/GMT-11"), # Samoa
    c("GST", "Etc/GMT-10"), # Guam
    c("UNK", "NA"), # Unknown
    c("UTC", "Etc/GMT+0"),
    c("GMT", "Etc/GMT+0"), # UTC
    c("ADT", "Etc/GMT+3"),
    c("AST", "Etc/GMT+4"),
    c("EDT", "Etc/GMT+4"),
    c("EST", "Etc/GMT+5"),
    c("ESt", "Etc/GMT+5"), # EST
    c("ESY", "NA"), # EST
    c("CDT", "Etc/GMT+5"),
    c("CST", "Etc/GMT+6"),
    c("CSt", "Etc/GMT+6"), # CST
    c("CSC", "NA"), # CST
    c("SCT", "NA"), # CST
    c("MDT", "Etc/GMT+6"),
    c("MST", "Etc/GMT+7"),
    c("PDT", "Etc/GMT+7"),
    c("PST", "Etc/GMT+8"),
    c("AKS", "Etc/GMT+9"),
    c("HST", "Etc/GMT+10")
))
names(timezone_transform) <- c("TIME_ZONE", 'timezone')
dat <- merge(dat, timezone_transform, sort=F)
rows_removed <- nrow(dat[timezone == "NA",])
dat <- dat[timezone != "NA",]
```

This removed `r rows_removed` rows. We also remove rows with bad `BGN_TIME` values.


```{r }
begin_times <- parse_date_time(dat$BGN_TIM, c("HM", "HMS"))
bad_begin_times <- dat[is.na(begin_times), BGN_TIME]
dat <- dat[!is.na(begin_times)]
```

This removed `r length(bad_begin_times)` rows with begin times `r bad_begin_times`. We can now synthesize `begin_datetime` values.

```{r }
convert_to_datetime <- function(date_, time_, tz_){
    psx_date_ <- parse_date_time(date_, "mdY HMS")
    psx_time_ <- parse_date_time(time_, c("HM", "HMS"))
    make_datetime(
        year = year(psx_date_),
        month = month(psx_date_),
        day = day(psx_date_),
        hour = hour(psx_time_),
        min = minute(psx_time_),
        tz = as.character(tz_)
    )
}
dat[, begin_datetime := convert_to_datetime(BGN_DATE, BGN_TIME, timezone)]
```

This permits vizualizing the dataset's evolution, and that of `EVTYPE` values in particular.


### Visualization of `EVTYPE` evolution

We first extract the number of different event types used each year.

```{r }
counts_by_year <- dat %>%
    transmute(year = year(with_tz(begin_datetime, 'Etc/GMT+0')), EVTYPE) %>%
    unique() %>%
    count(year) %>%
    data.table()
```

We also extract the number of new event types added or removed each year.

```{r }
uses <- do.call(data.table, with(dat,
    aggregate(
        cbind(years = year(begin_datetime)),
        by = list(event_type = EVTYPE),
        function(yr) c(first = min(yr), last = max(yr))
    )
)) %>%
    mutate(years_used = years.last - years.first + 1)
additions <- uses %>%
    count(year = years.first) %>%
    select(year, added = n)
removals <- uses %>%
    count(year = years.last + 1) %>%
    select(year, removed = n)
updates <- counts_by_year %>%
    merge(additions, all=T ) %>%
    merge(removals, all=T) %>%
    {.[is.na(.)] <- 0; .} %>%
    mutate(active = cumsum(added) - cumsum(removed)) %>%
    select(-n) %>%
    filter(year < 2012)
```

We can now visualize the number of actively-used events each year, as well as additions of new types and retirements of old types.

```{r }
long_updates <- updates %>% melt(id.var = c('year'), value.name = 'count')
ggplot(long_updates, aes(x=year, y=count, color=variable)) + geom_line()
```

Over 400 new event are added between about 1993 and 1995, the majority of which are retired within a few years. The number of actively-used events continues to decline for a decade before stabilizing slightly below 50 around 2005. After 2006, exactly `r counts_by_year[2007 == year, n]` are used in each year.

```{r }
counts_by_year[2005 <= year,]
```

The number of distinct event types used between 2007 and 2011 is
`r length(unique(dat[(ymd("2007-1-1", tz='Etc/GMT+0') <= begin_datetime), EVTYPE]))`.

```{r }
event_types <- unique(dat[(ymd("2007-1-1", tz='Etc/GMT+0') <= begin_datetime), EVTYPE])
sort(event_types)
length(event_types)
```

These types are exactly the permitted storm data events listed in table 1, section 2.1.1 of the [National Weather Service Instruction (NWSI) 10-1605](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) dated August 17, 2007 (which, provided to us by our instructors, has in its publication date a hint).


### Extracting permitted events

Our usable data is thus limited to the period from 2007 through 2011. We extract this period for further processing.

```{r }
dat <- dat[(ymd("2007-1-1", tz='Etc/GMT+0') <= begin_datetime),]
```

To simplify troubleshooting we map `EVTYPE` values to names listed in NWSI 10-1605. `LANDSLIDE` maps to "Debris Flow", `HURRICANE` to "Hurricane (Typhoon)", and `VOLCANIC ASHFALL` to "Volcanic Ash". The remainder change capitalization only.
```{r }
event_transform <- data.frame(rbind(
    c("ASTRONOMICAL LOW TIDE", "Astronomical Low Tide"),
    c("AVALANCHE", "Avalanche"),
    c("BLIZZARD", "Blizzard"),
    c("COASTAL FLOOD", "Coastal Flood"),
    c("COLD/WIND CHILL", "Cold/Wind Chill"),
    c("LANDSLIDE", "Debris Flow"),
    c("DENSE FOG", "Dense Fog"),
    c("DENSE SMOKE", "Dense Smoke"),
    c("DROUGHT", "Drought"),
    c("DUST DEVIL", "Dust Devil"),
    c("DUST STORM", "Dust Storm"),
    c("EXCESSIVE HEAT", "Excessive Heat"),
    c("EXTREME COLD/WIND CHILL", "Extreme Cold/Wind Chill"),
    c("FLASH FLOOD", "Flash Flood"),
    c("FLOOD", "Flood"),
    c("FREEZING FOG", "Freezing Fog"),
    c("FROST/FREEZE", "Frost/Freeze"),
    c("FUNNEL CLOUD", "Funnel Cloud"),
    c("HAIL", "Hail"),
    c("HEAT", "Heat"),
    c("HEAVY RAIN", "Heavy Rain"),
    c("HEAVY SNOW", "Heavy Snow"),
    c("HIGH SURF", "High Surf"),
    c("HIGH WIND", "High Wind"),
    c("HURRICANE", "Hurricane (Typhoon)"),
    c("ICE STORM", "Ice Storm"),
    c("LAKE-EFFECT SNOW", "Lake-Effect Snow"),
    c("LAKESHORE FLOOD", "Lakeshore Flood"),
    c("LIGHTNING", "Lightning"),
    c("MARINE HAIL", "Marine Hail"),
    c("MARINE HIGH WIND", "Marine High Wind"),
    c("MARINE STRONG WIND", "Marine Strong Wind"),
    c("MARINE THUNDERSTORM WIND", "Marine Thunderstorm Wind"),
    c("RIP CURRENT", "Rip Current"),
    c("SEICHE", "Seiche"),
    c("SLEET", "Sleet"),
    c("STORM SURGE/TIDE", "Storm Surge/Tide"),
    c("STRONG WIND", "Strong Wind"),
    c("THUNDERSTORM WIND", "Thunderstorm Wind"),
    c("TORNADO", "Tornado"),
    c("TROPICAL DEPRESSION", "Tropical Depression"),
    c("TROPICAL STORM", "Tropical Storm"),
    c("TSUNAMI", "Tsunami"),
    c("VOLCANIC ASHFALL", "Volcanic Ash"),
    c("WATERSPOUT", "Waterspout"),
    c("WILDFIRE", "Wildfire"),
    c("WINTER STORM", "Winter Storm"),
    c("WINTER WEATHER", "Winter Weather")
))
names(event_transform) <- c("EVTYPE", "event_type")
dat <- merge(dat, event_transform, sort=F)
```


### Transforming property- and crop-damage data

Our property- and crop-damage data appear as fields `PROPDMG/CROPDMG` (numeric) and `PROPDMGEXP/CROPDMGEXP` (character). The former appear to be significands, and the latter exponents that we now explore.

```{r }
unique(dat[, PROPDMGEXP])
unique(dat[, CROPDMGEXP])
```

The symbol '0' is used once with `PROPDMG` value also zero, so can be assumed to represent 1e0.

```{r }
dat[(PROPDMGEXP == '0') | (CROPDMGEXP == '0'),]
```

Use of symbols 'K' (thousands), 'M' (millions), and 'B' (billions) is consistent with NWSI 10-1605 documentation. We transform exponent symbols to numeric multipliers.

```{r }
damage_exponent_transform <- data.frame(rbind(
    c("B", 1e9), # Billion
    c("M", 1e6), # Million
    c("K", 1e3), # Thousand
    c("0", 1e0)  # One
))
names(damage_exponent_transform) <- c("PROPDMGEXP", 'property_damage_multiplier')
dat <- merge(dat, damage_exponent_transform, sort=F)
names(damage_exponent_transform) <- c("CROPDMGEXP", 'crop_damage_multiplier')
dat <- merge(dat, damage_exponent_transform, sort=F)
```

We can now synthesize property- and crop-damage values.

```{r }
dat[, property_damage := PROPDMG * as.numeric(property_damage_multiplier)]
dat[, crop_damage := CROPDMG * as.numeric(crop_damage_multiplier)]
```


### Tidying

Our final processing step removes unused fields.

```{r }
tdy <- dat %>%
    select(
        begin_datetime,
        event_type,
        injuries = INJURIES,
        fatalities = FATALITIES,
        property_damage,
        crop_damage,
    )
```

The remaining tidy fields have the following meanings:

- `event_type`: One of 48 permitted storm-event types listed in NWSI 10-1605 as of August 17, 2007. Type: factor.
- `begin_datetime`: The date and time at start of the event. Type: `POSIXct`.
- `injuries`: The number of direct injuries caused by the event. Type: integer.
- `fatalities`: The number of direct fatalities caused by the event. Type: integer.
- `property_damage`: The dollar amount of direct property damage caused by the event. Type: numeric.
- `crop_damage`: The dollar amount of direct crop damage caused by event. Type: numeric.

We verify that no integer or numeric data are missing.

```{r }
with(tdy, sum(is.na(c(injuries, fatalities, property_damage, crop_damage))))
```

Finally, we save the tidy data.

```{r }
fwrite(tdy, tdy_pth)
```


### Quality assessment: consequences of limiting data to a five-year span

Our usable data cannot answer our original questions. We develop an explanation below, first discussing problems preventing comparative analysis, their solutions, and problems caused by those solutions. The latter prevent answering our original questions. In their place we will pose limited versions our data _can_ answer.

In the original data, the number of distinct event types ranges from one to over 400 for any given year. This has at least three causes:

- At different times, very different populations of event types were sampled.
- At different times, very different recording methods were used. At times multiple events of different types were sytematically recorded in single observations. at other times such events were systematically recorded separately.
- There are many examples of events of a single type designated at different times by different spellings.

Different populations and methods at different times result in incomparable data, prevent comparative analysis. Different spellings require extensive by-hand curation during processing. We solve these problems by constraining our dataset to the 48 permitted events listed in NWSI 10-1605, which permits comparative analysis.

But in doing so we discard over 65 years of data. The remainder span five years, or less than ten percent. Moreover, four global El Niño events lasting over five years occurred from 1950 to 2011, with several strong interspersed La Niña events associated with distinctly different weather. Weather during El Niño and La Niña are not comparable, and the period spanned by our remaining data coincides with predominantly La Niña events. Consequently, the conclusions in this analysis cannot generalize to certain other, or larger, time spans, so cannot answer with generality the posed questions.

We can instead answer the more limited questions:

- Across the United States _from 2007 to 2011_, which types of events are most harmful to population health?
- Across the United States _from 2007 to 2011_, which types of events have the greatest economic cost?


# Results

```{r , eval=F, include=F, results="hide"}
library(rmarkdown)
rmarkdown::render(
    "severe-weather-writeup_180630-1512.Rmd",
    output_dir = "text",
    clean = T
)
```
