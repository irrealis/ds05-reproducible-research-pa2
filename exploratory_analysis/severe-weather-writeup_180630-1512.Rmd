---
title: "Health and Financial Impact of Severe-Weather Events Between 2005 and 2011"
---

```{r , eval=F, include=F, results="hide"}
setwd("/media/kaben/Work/Repos/irrealis/ds05-reproducible-research-pa2/exploratory_analysis/")
```

## Synopsis

## Data Processing

We begin by loading required libraries _data.table_ and _dplyr_ for data manipulation, _lubridate_ for handling dates, and _ggplot2_ for plotting.

```{r }
library(data.table)
library(ggplot2)
library(dplyr)
library(lubridate)
```

We set hard-coded analysis parameters, most importantly the raw data URL. The remaining convenience parameters organize analysis files.

```{r }
# Data subdirectory.
dat_dir <- "data"
# Raw data subdirectory.
raw_dir <- file.path(dat_dir, "raw")
# Intermediate data subdirectory.
int_dir <- file.path(dat_dir, "intermediate")
# Clean data subdirectory.
cln_dir <- file.path(dat_dir, "processed")

# Raw-data URL.
raw_url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
# Raw-data filename.
raw_fnm <- "StormData.csv.bz2"
# Raw-data path.
raw_pth <- file.path(raw_dir, raw_fnm)

# Cached data.
cch_fnm <- "StormData.csv"
cch_pth <- file.path(int_dir, cch_fnm)
```

We create any missing analysis subdirectories.

```{r }
if(!dir.exists(dat_dir)){ dir.create(dat_dir) }
if(!dir.exists(raw_dir)){ dir.create(raw_dir) }
if(!dir.exists(int_dir)){ dir.create(int_dir) }
if(!dir.exists(cln_dir)){ dir.create(cln_dir) }
```

We define a convenience function to load raw data, downloading and caching if missing.

```{r }
fetch_if_missing_then_load <- function(url_, raw_pth_, dat_pth_){
    if(!file.exists(dat_pth_)){
        if(!file.exists(raw_pth_)){ download.file(url_, raw_pth_) }
        fwrite(read.csv(raw_pth_), dat_pth_)
    }
    fread(dat_pth_)
}
```

We then load raw data.

```{r }
dat <- fetch_if_missing_then_load(raw_url, raw_pth, cch_pth)
```

This analysis uses the following columns:

- `EVTYPE` (weather-event types)
- `FATALITIES` and `INJURIES`
- `PROPDMG` and `PROPDMGEXP` (property-damage values)
- `CROPDMG` and `CROPDMGEXP` (crop-damage values)
- `BGN_DATE`, `BGN_TIME`, and `TIME_ZONE` (weather-event starting dates and times)

We discard all others, and verify the desired columns are present.

```{r }
dat[, c("STATE__", "COUNTY", "COUNTYNAME", "STATE", "BGN_RANGE", "BGN_AZI", "BGN_LOCATI", "END_DATE", "END_TIME", "COUNTY_END", "COUNTYENDN", "END_RANGE", "END_AZI", "END_LOCATI", "LENGTH", "WIDTH", "F", "MAG", "WFO", "STATEOFFIC", "ZONENAMES", "LATITUDE", "LONGITUDE", "LATITUDE_E", "LONGITUDE_", "REMARKS", "REFNUM") := NULL]

str(dat)
```

From [Storm Data Documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) we expect 48 permitted storm data event types (see sec. 2.1), but find `r length(unique(dat$EVTYPE))` distinct types in our data.

```{r }
length(unique(dat$EVTYPE))
```

The first few events suggest that spelling variants and event conflations are causes. For example, `TSTM WIND`, `THUNDERSTORM WINDS`, `THUNDERSTORM WIND`, `THUNDERSTORM WINS` all appear to represent "Thunderstorm Wind", and `HURRICANE OPAL/HIGH WINDS` represents two separate (if related) event types.

```{r }
unique(dat$EVTYPE)[1:20]
```

Some `r length(dat[grepl("Summary", EVTYPE, ignore.case = F), EVTYPE])` rows appear to summarize other events, but record no injuries, fatalities, or property/crop damage, so should be excluded from analysis.

```{r }
dat[grepl("Summary", EVTYPE, ignore.case = F), EVTYPE][1:5]
sum(dat[grepl("Summary", EVTYPE, ignore.case = F), c(INJURIES, FATALITIES, PROPDMG, CROPDMG)])
```

Only three event types are recorded for the 1950s (and only `r unique(dat[grepl("1951", BGN_DATE, ignore.case = F), EVTYPE])` events for the early '50s).

```{r }
unique(dat[grepl("195[[:digit:]]", BGN_DATE, ignore.case = F), EVTYPE])
```

The [National Oceanic and Atmospheric Administration (NOAA) Storm Events Database page](https://www.ncdc.noaa.gov/stormevents/details.jsp) states that only tornado events are represented for 1950 through 1954, and tornado, thunderstorm wind, and hail for 1955 through 1995, which seems to agree with our findings. However, the page states that 48 event types are used for 1996 to present, which does not explain the `r length(unique(dat$EVTYPE))` distinct types we find. But it suggests construction of a time series as part of a processing strategy to identify and extract a dataset suitable for analysis. Accordingly we synthesize a `begin_datetime` field for each row using `BGN_DATE`, `BGN_TIME`, and `TIME_ZONE`.

We first transform `TIME_ZONE` for compatibility with _R_ and _lubridate_. Of the distinct values of `TIME_ZONE`, two appear to be capitalization variants of "EST" and "CST" (`ESt` and `CSt`, respectively), one appears to represent "Unknown" (`UNK`), and three appear to be misspellings (`ESY`, `CSC`, and `SCT`).

```{r }
unique(dat$TIME_ZONE)
```

We construct and apply the transformation, then remove rows with unknown or misspelled values for `TIME_ZONE`.

```{r }
timezone_transform <- data.frame(rbind(
    c("SST", "Etc/GMT-11"), # Samoa
    c("GST", "Etc/GMT-10"), # Guam
    c("UNK", "NA"), # Unknown
    c("UTC", "Etc/GMT+0"),
    c("GMT", "Etc/GMT+0"), # UTC
    c("ADT", "Etc/GMT+3"),
    c("AST", "Etc/GMT+4"),
    c("EDT", "Etc/GMT+4"),
    c("EST", "Etc/GMT+5"),
    c("ESt", "Etc/GMT+5"), # EST
    c("ESY", "NA"), # EST
    c("CDT", "Etc/GMT+5"),
    c("CST", "Etc/GMT+6"),
    c("CSt", "Etc/GMT+6"), # CST
    c("CSC", "NA"), # CST
    c("SCT", "NA"), # CST
    c("MDT", "Etc/GMT+6"),
    c("MST", "Etc/GMT+7"),
    c("PDT", "Etc/GMT+7"),
    c("PST", "Etc/GMT+8"),
    c("AKS", "Etc/GMT+9"),
    c("HST", "Etc/GMT+10")
))
names(timezone_transform) <- c("TIME_ZONE", 'timezone')
dat <- merge(dat, timezone_transform, sort=F)
rows_removed <- nrow(dat[timezone == "NA",])
dat <- dat[timezone != "NA",]
```

This has removed `r rows_removed` rows. We also remove rows with bad `BGN_TIME` values.


```{r }
begin_times <- parse_date_time(dat$BGN_TIM, c("HM", "HMS"))
bad_begin_times <- dat[is.na(begin_times), BGN_TIME]
dat <- dat[!is.na(begin_times)]
```

This has removed `r length(bad_begin_times)` rows with begin times `r bad_begin_times`.


## Results

```{r , eval=F, include=F, results="hide"}
library(rmarkdown)
rmarkdown::render(
    "severe-weather-writeup_180630-1512.Rmd",
    output_dir = "text",
    clean = T
)
```
